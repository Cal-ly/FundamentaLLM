vocab_size: 73
d_model: 512
num_heads: 8
num_layers: 6
sequence_length: 256
dropout: 0.1
ffn_expansion: 4
pos_encoding: learned
