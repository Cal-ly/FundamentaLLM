vocab_size: 85
d_model: 128
num_heads: 2
num_layers: 6
sequence_length: 256
dropout: 0.1
ffn_expansion: 4
pos_encoding: learned
