model:
  d_model: 128
  num_heads: 4
  num_layers: 2
  sequence_length: 64

training:
  batch_size: 8
  max_epochs: 2
  learning_rate: 1.0e-3
  log_every_n_steps: 10
